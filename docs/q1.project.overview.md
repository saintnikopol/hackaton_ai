I'll answer as a world-famous real-time audio processing and speech recognition expert with the IEEE Signal Processing Society Award.

**TL;DR**: WhisperLive is a client-server system where the server runs OpenAI Whisper models for real-time transcription, and clients stream audio via WebSocket. To connect an Electron app, you need to capture audio, send it to the server in 16kHz format, and receive transcription results.

## What WhisperLive Server Does

The **WhisperLive Server** is the core transcription engine that:

1. **Runs Whisper Models**: Supports multiple backends:
   - `faster_whisper` (4x faster than OpenAI's implementation)
   - `tensorrt` (NVIDIA GPU acceleration)
   - `openvino` (Intel CPU/GPU optimization)

2. **Handles WebSocket Connections**: Manages multiple client connections simultaneously with configurable limits (`max_clients`, `max_connection_time`)

3. **Processes Audio Streams**: 
   - Receives 16kHz audio chunks from clients
   - Applies Voice Activity Detection (VAD) to filter silence
   - Performs real-time transcription using Whisper models
   - Handles language detection automatically

4. **Streams Results**: Sends transcription segments back to clients in real-time via WebSocket

**Starting the server:**
```bash
# Faster Whisper backend
python3 run_server.py --port 9090 --backend faster_whisper

# TensorRT backend (GPU acceleration)
python3 run_server.py --port 9090 --backend tensorrt --trt_model_path "/path/to/model"

# OpenVINO backend (Intel optimization)  
python3 run_server.py --port 9090 --backend openvino
```

## What WhisperLive Client Does

The **WhisperLive Client** handles audio capture and communication:

1. **Audio Capture**: Captures audio from various sources:
   - Microphone input
   - Audio files
   - RTSP/HLS streams
   - Browser tab audio (extensions)

2. **Audio Processing**:
   - Resamples audio to 16kHz (required format)
   - Converts to float32 format
   - Chunks audio for streaming

3. **WebSocket Communication**:
   - Connects to server via WebSocket
   - Sends configuration (language, model, task)
   - Streams audio chunks continuously
   - Receives and displays transcription results

## Connecting Electron App to WhisperLive

To integrate your Electron app with WhisperLive, you need to implement the client-side functionality:

### 1. Audio Capture in Electron

```javascript
// In your Electron renderer process
navigator.mediaDevices.getUserMedia({ audio: true })
  .then(stream => {
    const audioContext = new AudioContext({ sampleRate: 16000 });
    const source = audioContext.createMediaStreamSource(stream);
    const processor = audioContext.createScriptProcessor(4096, 1, 1);
    
    processor.onaudioprocess = (event) => {
      const audioData = event.inputBuffer.getChannelData(0);
      // Send audioData to WhisperLive server
      sendAudioChunk(audioData);
    };
    
    source.connect(processor);
    processor.connect(audioContext.destination);
  });
```

### 2. WebSocket Connection Setup

```javascript
// Connect to WhisperLive server
const socket = new WebSocket('ws://localhost:9090');

// Send configuration on connection
socket.onopen = () => {
  socket.send(JSON.stringify({
    uid: generateUUID(),
    language: 'en',  // or null for auto-detection
    task: 'transcribe',  // or 'translate'
    model: 'small',
    use_vad: true,
    max_clients: 4,
    max_connection_time: 600
  }));
};

// Handle transcription results
socket.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.segments) {
    // Display transcription segments
    displayTranscription(data.segments);
  }
};
```

### 3. Audio Resampling and Streaming

```javascript
// Resample audio to 16kHz (adapted from browser extension code)
function resampleTo16kHz(audioData, origSampleRate = 44100) {
  const data = new Float32Array(audioData);
  const targetLength = Math.round(data.length * (16000 / origSampleRate));
  const resampledData = new Float32Array(targetLength);
  
  const springFactor = (data.length - 1) / (targetLength - 1);
  resampledData[0] = data[0];
  resampledData[targetLength - 1] = data[data.length - 1];
  
  for (let i = 1; i < targetLength - 1; i++) {
    const index = i * springFactor;
    const leftIndex = Math.floor(index);
    const rightIndex = Math.ceil(index);
    const fraction = index - leftIndex;
    resampledData[i] = data[leftIndex] + (data[rightIndex] - data[leftIndex]) * fraction;
  }
  
  return resampledData;
}

function sendAudioChunk(audioData) {
  if (socket.readyState === WebSocket.OPEN) {
    const resampledAudio = resampleTo16kHz(audioData, audioContext.sampleRate);
    socket.send(resampledAudio.buffer);
  }
}
```

### 4. Complete Electron Integration Example

```javascript
class WhisperLiveClient {
  constructor(host = 'localhost', port = 9090) {
    this.socket = new WebSocket(`ws://${host}:${port}`);
    this.isRecording = false;
    this.setupWebSocket();
  }
  
  setupWebSocket() {
    this.socket.onopen = () => {
      this.socket.send(JSON.stringify({
        uid: this.generateUUID(),
        language: null,  // Auto-detect
        task: 'transcribe',
        model: 'small',
        use_vad: true
      }));
    };
    
    this.socket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.segments) {
        this.onTranscription(data.segments);
      }
    };
  }
  
  async startRecording() {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioContext = new AudioContext({ sampleRate: 16000 });
    const source = audioContext.createMediaStreamSource(stream);
    const processor = audioContext.createScriptProcessor(4096, 1, 1);
    
    processor.onaudioprocess = (event) => {
      if (this.isRecording) {
        const audioData = event.inputBuffer.getChannelData(0);
        this.socket.send(audioData.buffer);
      }
    };
    
    source.connect(processor);
    processor.connect(audioContext.destination);
    this.isRecording = true;
  }
  
  stopRecording() {
    this.isRecording = false;
    this.socket.send("END_OF_AUDIO");
  }
  
  onTranscription(segments) {
    // Handle transcription results in your Electron app
    console.log('Transcription:', segments);
  }
  
  generateUUID() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
      const r = Math.random() * 16 | 0;
      const v = c === 'x' ? r : (r & 0x3 | 0x8);
      return v.toString(16);
    });
  }
}

// Usage in your Electron app
const whisperClient = new WhisperLiveClient();
whisperClient.startRecording();
```

This setup allows your Electron app to stream audio directly to WhisperLive for real-time transcription, following the same protocol used by the browser extensions.
